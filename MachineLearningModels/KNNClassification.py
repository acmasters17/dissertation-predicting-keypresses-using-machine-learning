import pandas as pd
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import sklearn.model_selection

# Load csv generated by DatasetGenerator directory
data = pd.read_csv('../DatasetGenerator/DataSets/test.csv')

# Separate features and label
X = data.iloc[:,:-1].values 
y = data.iloc[:,20].values

# Test size specifies how much of the data you want to set aside for the testing set. 
# Random_state parameter is just a random seed we can use.
# You can use it if you'd like to reproduce these specific results.

X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.40, random_state=42)

# Create KNN model
KNN_model = KNeighborsClassifier(n_neighbors=10)

# Train model
KNN_model.fit(X_train, y_train)

# Test Model
KNN_prediction = KNN_model.predict(X_test)

# Display performance measures of model
print("-------------------")
print("KNN Model")
print("Accuracy for KNN : " + str(accuracy_score(KNN_prediction, y_test)))
print("Classification Report for KNN with 5 neighbours")
print(classification_report(KNN_prediction, y_test, zero_division=0))
print("-------------------")

# Visualise data
# figure = plt.figure()
# # Plot the training points
# plt.scatter(
#             X_train[:, 0], X_train[:, 1], c=y_train, edgecolors="k"
# )
# plt.show()
