import pandas as pd
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedShuffleSplit
import matplotlib.pyplot as plt 

# Load csv generated by DatasetGenerator directory
data = pd.read_csv('../DatasetGenerator/DataSets/test.csv')

# Separate features and label
X = data.iloc[:,:-1].values 
y = data.iloc[:,20].values

# Using stratified sampling
sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)

# choose k between 1 to 31
k_range = range(1, 31)
k_scores = []

# Create KNN model
KNN_model = KNeighborsClassifier

# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation
for k in k_range:
    # Create KNN model
    KNN_model = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(KNN_model, X, y, cv=sss, scoring="accuracy")
    k_scores.append(scores.mean())

# plot to see clearly
plt.plot(k_range, k_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Cross-Validated Accuracy')
plt.show()



# Display performance measures of model
print("-------------------")

print("Best Accuracy - " + str(max(k_scores)))
print("-------------------")

