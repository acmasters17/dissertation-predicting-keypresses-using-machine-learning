import pandas as pd
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, train_test_split
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from config import INPUT_CSV_FILENAME, RANDOM_STATE, FOLDS
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler








plt.style.use('ggplot')

# Load csv generated by DatasetGenerator directory
data = pd.read_csv('../DatasetGenerator/DataSets/' + INPUT_CSV_FILENAME)

# Separate features and label
X = data.iloc[:, :-1].values
# X = np.concatenate([X, X])
y = data.iloc[:, 20].values
# y = np.concatenate([y, y])

# Separate data into outer training and testing
X_outer_train, X_outer_test, y_outer_train, y_outer_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_STATE)

# Run all models via pipelines
KNNPipe = make_pipeline(StandardScaler(), KNeighborsClassifier())
LinearPipe = make_pipeline(StandardScaler(), SVC(kernel="linear"))
PolyPipe = make_pipeline(StandardScaler(), SVC(kernel="poly"))
RBFPipe = make_pipeline(StandardScaler(), SVC(kernel="rbf"))
LogisticRegressionPipe = make_pipeline(StandardScaler(), LogisticRegression(solver="newton-cg"))

print("\n")
print("Pipeline Results for " + INPUT_CSV_FILENAME)
print("\n")
highestPipe = KNNPipe

KNNPipe.fit(X_outer_train, y_outer_train)
print("KNN - ", KNNPipe.score(X_outer_test, y_outer_test))

LinearPipe.fit(X_outer_train, y_outer_train)
print("Linear SVM - ", LinearPipe.score(X_outer_test, y_outer_test))

highestPipe = LinearPipe if LinearPipe.score(X_outer_test, y_outer_test) > highestPipe.score(X_outer_test, y_outer_test) else highestPipe

PolyPipe.fit(X_outer_train, y_outer_train)
print("Poly SVM - ", PolyPipe.score(X_outer_test, y_outer_test))

highestPipe = PolyPipe if PolyPipe.score(X_outer_test, y_outer_test) > highestPipe.score(X_outer_test, y_outer_test) else highestPipe

RBFPipe.fit(X_outer_train, y_outer_train)
print("RBF SVM - ", RBFPipe.score(X_outer_test, y_outer_test))

highestPipe = RBFPipe if RBFPipe.score(X_outer_test, y_outer_test) > highestPipe.score(X_outer_test, y_outer_test) else highestPipe

LogisticRegressionPipe.fit(X_outer_train, y_outer_train)
print("Logistic Regression with newton-cg solver - ", LogisticRegressionPipe.score(X_outer_test, y_outer_test))

highestPipe = LogisticRegressionPipe if LogisticRegressionPipe.score(X_outer_test, y_outer_test) > highestPipe.score(X_outer_test, y_outer_test) else highestPipe

print("\n")

print(highestPipe.get_params(True))

model = SVC()
scaler = StandardScaler()
X_scaled_train = scaler.fit_transform(X_outer_train,y_outer_train)
model.fit(X_scaled_train,y_outer_train)
print(f1_score(y_outer_test,model.predict(scaler.fit_transform(X_outer_test)),average="weighted"))
print(classification_report(y_outer_test,model.predict(scaler.fit_transform(X_outer_test)),zero_division=0))




# scaler = preprocessing.StandardScaler().fit(X_outer_train)

# X_scaled = scaler.transform(X_outer_train)


# # Using stratified sampling on training set
# sss = StratifiedShuffleSplit(n_splits=FOLDS, test_size=0.33, random_state=RANDOM_STATE)


# # define search space
# space = dict()
# space['C'] = [0.1, 0.3, 0.5, 1]

# outer_results = list()

# # 10 fold cross validation
# for train_index, test_index in sss.split(X_outer_train, y_outer_train):
#     # For each fold perform nested cross validation

#     # Extract training and testing data
#     X_inner_train, X_inner_test = X_outer_train[train_index], X_outer_train[test_index]
#     y_inner_train, y_inner_test = y_outer_train[train_index], y_outer_train[test_index]

# 	# configure the cross-validation procedure
#     cv_inner = StratifiedShuffleSplit(n_splits=4, random_state=RANDOM_STATE)

# 	# define the model
#     model = LogisticRegression(random_state=RANDOM_STATE)
	
# 	# define search
#     search = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)
#     # execute search
#     result = search.fit(X_inner_train, y_inner_train)
# 	# get the best performing model fit on the whole training set
#     best_model = result.best_estimator_
# 	# evaluate model on the hold out dataset
#     yhat = best_model.predict(X_inner_test)
# 	# evaluate the model
#     acc = accuracy_score(y_inner_test, yhat)
# 	# store the result
#     outer_results.append(acc)
# 	# report progress
#     print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))



