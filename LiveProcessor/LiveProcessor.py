import numpy as np
import pandas as pd
import pyaudio
import wave
from config import INPUT_CSV_FILENAME, PREDICTION_SESSION_NAME
import librosa
import sox
from sklearn.neighbors import KNeighborsClassifier
import warnings
warnings.filterwarnings('ignore', '.*output_file.*', )


# Load csv generated by DatasetGenerator directory
data = pd.read_csv('../DatasetGenerator/DataSets/' + INPUT_CSV_FILENAME)

# Separate features and label
X = data.iloc[:, :-1].values
# X = np.concatenate([X, X])
y = data.iloc[:, 20].values
# y = np.concatenate([y, y])

model = KNeighborsClassifier(n_neighbors=8)

model.fit(X, y)

p = pyaudio.PyAudio()
info = p.get_host_api_info_by_index(0)
print(info)
numdevices = info.get('deviceCount')
print(numdevices)
for i in range(0, numdevices):
        if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:
            print ("Input Device id ", i, " - ", p.get_device_info_by_host_api_device_index(0, i).get('name'))

# Start recording and processing
while True:
    # Record 2 second clips then process them and predict using fully trained model above
    chunk = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 44100
    RECORD_SECONDS = 10
    

    p = pyaudio.PyAudio()

    stream = p.open(format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                input_device_index=1,
                frames_per_buffer=chunk)


    print("Recording Audio")
    frames = []
    for i in range(0, int(RATE / chunk * RECORD_SECONDS)):
        data = stream.read(chunk)
        frames.append(data)

    print ("Finished Recording")
    stream.stop_stream()
    stream.close()
    p.terminate()

    print("Creating File")
    # write data to test WAVE file
    wf = wave.open("buffer.wav", 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

    print("Removing Silence and white noise")
    tfm = sox.Transformer()
    tfm.trim(0.3)
    tfm.build_file('./buffer.wav', './silenced_buffer.wav')
    


    print("Processing of recorded audio")
    # Load file into librosa
    y, sr = librosa.load("./silenced_buffer.wav", sr=None)

    if(y is None or len(y) == 0):
        print("Prediction")
        print("Nothing")
    else:
        # Create an mfcc for file
        mfccForFile = librosa.feature.mfcc(y=y, sr=sr)

        datapoint = [] 
        for columnList in mfccForFile:
            # Calculate average mean
            total = 0
            for value in columnList:
                total += value

            mean = total / len(columnList)
            datapoint.append(mean)

        # We now have an x datapoint so predict
        reshapedDatapoint = np.reshape(datapoint, (1,-1))
        output = model.predict(reshapedDatapoint)

        print("Prediction")
        print(output)

        print("Writing to File...")
        character = output[0]
        if character == "Space":
            character = " "
        if character == "FullStop":
            character = "."
        
        f = open(PREDICTION_SESSION_NAME, "a")
        f.write(character)
        f.close()
        print("Finished Writing")

    

    


